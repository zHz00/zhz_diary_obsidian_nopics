Траск Э. // Грокаем глубокое обучение
=====================================

  
2021-06-29, 02:35  
 Нейронными сетями я не занимаюсь, но они меня пугают. Я решил, что страх во мне -- от того, что я не понимаю, как это работает. Поэтому надо прочитать что-нибудь по теме, просветиться. Что я и сделал.   
   
 И теперь боюсь ещё больше.   
   
 Первую треть книжки было откровенно скучно, потому что разбирались какие-то простейшие случаи, близкие по возможностям к пид-регуляторам, у которых автоматически подбираются коэффициенты. Но потом пошли сети со скрытым слоем. И оказалось, что то, что происходит в скрытых слоях, об'яснить и проанализировать -- затруднительно.   
   
 Хотя автор пишет, что предварительная подготовка для книжки не нужна, Питон для понимания листингов знать всё-таки надо -- и, в особенности, библиотеку NumPy. Я прочитал одну книжку по питону, но листинги второй половины книги давались уже с трудом -- не столько из-за синтаксиса, сколько из-за плохого понимания, что конкретно происходит в той или иной строчке. И вот отсюда следует одна из моих основных претензий к книжке: по листингам неясно, какая размерность у каждой переменной. Это надо выводить самому, читая листинг с самого начала. И следить надо за каждой переменной по отдельности. Следовало бы подписывать это в комментариях.   
   
 Тема, которую я не понял совершенно, называется "автоматическое дифференцирование при обратном распространении". Боюсь, вторую половину книги придётся перечитать.   
   
 Вторая претензия -- к переводу. Все термины переведены на русский язык, при этом английские термины в скобках не приводятся. Да, я очень доволен, что русскоязычная научно-инженерная среда имеет собственные, незаимствованные термины почти во всех областях деятельности, но Россия (пока ещё) не в информационной изоляции.   
   
 В книжки рассмотрены все широко известные области применения нейронных сетей:   
 1) Предсказание результата по предыдущим данным (видимо, так составляются рекомендации ютьюба)   
 2) Анализ изображений   
 3) Анализ текстов   
 4) Генерация текстов   
   
 После чтения мне стало примерно понятно, как всё это работает. Но возникает ощущение некоторого... шаманства, что ли. Наверное, это из-за того, что автор оставил в тексте мало математики. Складывается впечатление, что когда в нейронной сети возникает какая-либо проблема, типа переобучения, мы, пользуясь тем, что нейронная сеть -- это саморегулирующаяся система, придумываем какой-нибудь костыль, который нивелирует проблему не на корню, а в первом приближении. А дальше сеть сама разберётся и обучится.   
   
 Наверное, я ещё какую-нибудь книжку прочитаю, более углублённую, чтобы разобраться, так это или не так.   
  
<https://diary.ru/~zHz00/p220775005_trask-je-grokaem-glubokoe-obuchenie.htm>  
  
Теги:  
[[Программирование]]  
[[Книги]]  
ID: p220775005  


(Комментариев нет)
------------------